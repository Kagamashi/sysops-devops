# root or proxy_pass (reverse proxy)

user  www-data;        # system user that runs NGINX processes: nginx, www-data, nobody
worker_processes auto; # number of worker processes NGINX spawns to handle requests; auto sets it to the number of CPU cores
error_log /var/log/nginx/error.log; # path to the NGINX error log file
pid /run/nginx.pid;    # path to the NGINX process ID file


# #events block defines how NGINX should handle connections and events
events {
    worker_connections 1024; # maximum number of connections each worker process can handle
}


## http block defines global settings for the HTTP server
http {
    include /etc/nginx/mime.types;          # includes MIME types for file extensions (supported file types)
    include /etc/nginx/conf.d/*.conf;       # includes additional configuration files
    include /etc/nginx/sites-enabled/*;     # includes server blocks for different sites
    default_type  application/octet-stream; # default MIME type for unknown file types
    access_log /var/log/nginx/access.log;   # path to the NGINX access log file
    sendfile on;                            # enables sendfile for faster file transfers
    keepalive_timeout 65;                   # maximum time a connection can remain open
}


## Rate Limiting and DDoS Protection
# Rate Limiting Requests - limit number of requests per second from a client to prevent abuse
limit_req_zone $binary_remote_addr zone=mylimit:10m rate=1r/s;
    # rate - specifies the maximum request rate
    # burst  - allow short burts of up to 20 requests before rate limiting starts
    # nodelay - immediately rejects excess requests instead of queuing them
server {
    location /api/ {
        limit_req zone=req_limit burst=20 nodelay;
        proxy_pass http://backend_server;
    }
}

# Limiting Concurrent Connections - restrict number of simultaneous connections from a single client
limit_conn_zone $binary_remote_addr zone=myconn:10m;
    # limit_conn_zone - defines shared memory zone (conn_limit) to track IP connections
    # limit_conn conn_limit 5; - restricts each client to 5 concurrent connections
server {
    location / {
        root /app/www;
        limit_conn conn_limit 5;
        proxy_pass http://backend_server;
    }
}


## server block defines how NGINX handles requests for a specific domain or IP
server {
    listen 80; # each server is distinguished by the port it listens on
    server_name site1.com;
    root /var/www/site1;
    index index.html;


    ## SSL and TLS Configuration
    return 301 https://$host$request_uri; # redirects all HTTP traffic to HTTPS

    ssl_certificate /etc/letsencrypt/live/example.com/fullchain.pem; # path to SSL certificate
    ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains; preload" always;
        # max-age - enforces HTTPS for one year
        # includeSubDomains - applies to all subdomains
        # preload - requests browser preload listing for HSTS

    ssl_protocols TLSv1.2 TLSv1.3; # enables only TLS 1.2 and 1.3 for security
    ssl_ciphers "ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384"; # uses strong cryptographic ciphers
    ssl_prefer_server_ciphers on;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;
    ssl_stapling on; # enables OCSP stapling for faster certificate validation
    ssl_stapling_verify on;
    resolver 8.8.8.8 8.8.4.4;


    # Protection Against Slowloris Attacks - type of DoS attack that keeps connections open without sending full requests
    client_body_timeout 10;   # closes slow clients that do not send request bodies within 10s
    client_header_timeout 10; # closes connections if request headers are not received within 10s
    keepalive_timeout 10;     # limits maximum keep-alive duration to 10s
    limit_conn conn_limit 10; # restricts concurrent connections per client


    ## Security Headers - to enhance security NGINX can send additional HTTP headers to protect against vulnerabilities
    add_header X-Frame-Options "SAMEORIGIN" always;     # prevents clickjacking by disallowing page embedding on other sites
    add_header X-XSS-Protection "1; mode=block" always; # enables build-in XSS filtering in modern browsers
    add_header X-Content-Type-Options "nosniff" always; # prevents MIME-type sniffing to mitigate certains attacks
    add_header Referrer-Policy "strict-origin-when-cross-origin" always;  # controls how much referrer info is sent
    add_header Permissions-Policy "geolocation=(), microphone=()" always; # limits browser access to sensitive features
    add_header Content-Security-Policy "default-src 'self'; script-src 'self' 'unsafe-inline';" always;  # restricts allowed sources of scripts, styles, and other content


    ## CORS (Cross-Origin Resource Sharing) - controlled access to resources from different origins
    location /api/ {
        add_header Access-Control-Allow-Origin "*";                             # allows requests from any domain (adjustable)
        add_header Access-Control-Allow-Methods "GET, POST, OPTIONS";           # defines allowed request types
        add_header Access-Control-Allow-Headers "Authorization, Content-Type";  # specifies permitted headers
        if ($request_method = OPTIONS) {        # handles OPTIONS preflight requests to avoid unnecessary server load
            return 204;
        }
    }

    # disable unused HTTP methods
    if ($request_method !~ ^(GET|POST|HEAD)$ ) { # DELETE, PUT, TRACE, OPTIONS..
        return 405;
    }

    # restrict access to hidden files (e.g. .git, .htaccess)
    location ~ /\. {
        deny all;
    }


    # NGINX allows custom error pages for various HTTP error codes
    error_page 404 /errors/404.html;
    error_page 500 502 503 504 /errors/50x.html;    # uses a generic error page for multiple server errors
    location /errors/ {
        internal; # marks error directory as internal, preventing direct user access
    }


    ## location blocks define how requests to specific paths are handled
    # static content
    location /static/ {
        alias /var/www/static/; # map /static/ path to different location on the filesystem
    }

    # dynamic content PHP
    location ~ \\.php$ {
        include fastcgi_params;
        fastcgi_pass unix:/run/php/php-fpm.sock; # directs PHP requests to PHP-FPM
        fastcgi_index index.php;
        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; # passes the script path to PHP
    }

    # dynamic content Python (using uWSGI)
    location / {
        include uwsgi_params;
        uwsgi_pass unix:/run/uwsgi/app.sock; # routes requests to uWSGI server running the Python app
    }

    # dynamic content Node.js (using Reverse Proxy)
    location / {
        proxy_pass http://127.0.0.1:3000; # directs traffic to Node.js backend running on port 3000
        proxy_set_header Host $host; # passes client headers to the backend service
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}


# gzip reduces file size for faster loading times
gzip on; # enables gzip compression
gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; # specifies MIME types to compress
gzip_comp_level 5; # compression level (1-9) with 9 being the highest compression but slower

# brotli is an alternative to Gzip with better compression rates
brotli on;
brotli_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;
brotli_comp_level 5;


## Load Balancing, Reverse Proxy, and Health Checks
# NGINX distributes requests in round-robin fashion by default, meaning each request is sent to the next available server in order
# NGINX can distribute incoming traffic among multiple backend servers using upstream directive
upstream backend_servers { # defines a group of backend servers
    server backend1.example.com weight=3; # backend1 receives 3x more traffic than backend2
    server backend2.example.com weight=1;
    server backend3.example.com max_fails=3; # marks server as failed after 3 failed attemps
    server backend4.example.com fail_timeout=30s; # server is marked as failed for 30 seconds before retrying

    # sticky sessions ensures a client always connects to the same backend
    ip_hash; # requests from the same IP address always go to the same server
    hash $request_uri consistent; # routes based on request URI, ensuring consistency across multiple requests

    least_conn; # sends traffic to the server with fewest active connections
    # sends traffic to the server with lowest response time
    least_time header; # balances based on fastest response time of backends initial response header
    least_time last_byte; # balances based on full response time, including body elivery

    health_check interval=5 fails=3 passes=2; # sends health check every 5 seconds, unhealthy after 3 failures, marks server as healthy after 2 successful checks
}

## Proxy Cache (for Reverse Proxy)
# NGINX can cache responses from upstream servers to improve performance and reduce backend load
proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=my_cache:10m; # defines cache storage location and cache zone (my_cache) with memory limit of 10MB
    # levels
    # keys_zone -
server {
    # multiple sites can exist on one server
    listen 80;
    server_name site2.com;
    root /var/www/site2;

    location /api/ {
        proxy_pass http://backend_server:5000;
        proxy_cache my_cache;       # enables caching for this location
        proxy_cache_valid 200 10m;  # specifies cache duration for different response codes
        proxy_cache_valid 404 1m;   # caches 404 Not Found responses for 1 minute
        proxy_cache_min_uses 3;     # ensures a response must be requested at least three times before it is cached
        proxy_cache_use_stale error timeout updating;     # if an upstream server is slow or fails, NGINX server a cached copy instead
        add_header X-Cache-Status $upstream_cache_status; # adds a custom header to responses showing wheter a cache hit (HIT), miss (MISS), or expired (EXPIRED) occured
    }
}

server {
    listen 80;
    server_name example.com;

    # proxy_pass is used to define the backend server where requests should be forwarded
    location /api/ {
        proxy_pass http://backend_server:5000; # requests to /api/ will be forwarded to http://backend_server:5000
    }

    # proxy_set_header is used to set or modify headers passed to upstream server
    location /api/ {
        proxy_pass http://backend_server:5000;
        proxy_set_header Host $host;    # passes the original Host header
        proxy_set_header X-Real-IP $remote_addr;    # passes the real client IP
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    # passes all forwarded IPs
    }

    # proxy_redirect rewrites Location and Refresh headers sent by the backend
    # ensures redirects sent by the backend work correctly when accessed via /app/
    location /app/ {
        proxy_pass http://backend_server:5000;
        proxy_redirect http://backend_server:5000/ /app/;
    }
}


## FastCGI Cache (for PHP apps)
fastcgi_cache_path /var/cache/nginx levels=1:2 keys_zone=php_cache:10m; # defines cache location and size
server {
    location ~ \.php$ {
        fastcgi_pass unix:/run/php/php-fpm.sock;
        fastcgi_cache php_cache;       # enables caching for PHP responses
        fastcgi_cache_valid 200 10m;   # caches successful responses for 10 minutes
        add_header X-Cache $upstream_cache_status;  # indicates whether a response was server from cache (HIT or MISS)
    }
}
